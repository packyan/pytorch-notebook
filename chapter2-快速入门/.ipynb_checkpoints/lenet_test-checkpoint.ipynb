{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda\n",
      "cuda is ready\n",
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "#from utils import progress_bar\n",
    "import argparse\n",
    "import os\n",
    "show = ToPILImage() # 可以把Tensor转成Image，方便可视化\n",
    "class lenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lenet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  \n",
    "        self.fc1   = nn.Linear(16*5*5, 100)  \n",
    "        self.fc2   = nn.Linear(100, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "\n",
    "\n",
    "#device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "device = 'cuda' if t.cuda.is_available() else 'cpu'\n",
    "print(\"Use \"+ str(device))\n",
    "net = lenet()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = t.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "    print(\"cuda is ready\")    \n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.99))\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "# 定义对数据的预处理\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(), # 转为Tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 归一化\n",
    "                             ])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# 训练集\n",
    "trainset = tv.datasets.CIFAR10(\n",
    "                    root='/home/pakcy/Downloads/pytorch-cifar-master/data', \n",
    "                    train=True, \n",
    "                    download=True,\n",
    "                    transform=transform)\n",
    "\n",
    "trainloader = t.utils.data.DataLoader(\n",
    "                    trainset, \n",
    "                    batch_size=128,\n",
    "                    shuffle=True, \n",
    "                    num_workers=2)\n",
    "\n",
    "# 测试集\n",
    "testset = tv.datasets.CIFAR10(\n",
    "                    '/home/pakcy/Downloads/pytorch-cifar-master/data',\n",
    "                    train=False, \n",
    "                    download=True, \n",
    "                    transform=transform)\n",
    "\n",
    "testloader = t.utils.data.DataLoader(\n",
    "                    testset,\n",
    "                    batch_size=100, \n",
    "                    shuffle=False,\n",
    "                    num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "#train \n",
    "t.set_num_threads(8)\n",
    "\n",
    "def train(epoch):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        # 输入数据\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward \n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()   \n",
    "        \n",
    "        # 更新参数 \n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印log信息\n",
    "        # loss 是一个scalar,需要使用loss.item()来获取数值，不能使用loss[0]\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        #progress_bar(batch_idx, len(trainloader), 'Loss: %.3f'\n",
    "            #% (running_loss/(batch_idx+1)))\n",
    "        if batch_idx % 20 == 0 or batch_idx == 390: # 每2000个batch打印一下训练状态\n",
    "            print('[%d, %5d] loss: %.3f' \\\n",
    "                  % (epoch+1, batch_idx+1, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "\n",
    "def test(epoch):\n",
    "    correct = 0 # 预测正确的图片数\n",
    "    total = 0 # 总共的图片数\n",
    "    # 由于测试的时候不需要求导，可以暂时关闭autograd，提高速度，节约内存\n",
    "    with t.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = t.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "        print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))\n",
    "        \n",
    "    \n",
    "def test2(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with t.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))\n",
    "            #progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                #% (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        t.save(state, './checkpoint/ckpt.t7')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.115\n",
      "[1,    21] loss: 2.233\n",
      "[1,    41] loss: 2.085\n",
      "[1,    61] loss: 1.990\n",
      "[1,    81] loss: 1.945\n",
      "[1,   101] loss: 1.901\n",
      "[1,   121] loss: 1.882\n",
      "[1,   141] loss: 1.828\n",
      "[1,   161] loss: 1.790\n",
      "[1,   181] loss: 1.756\n",
      "[1,   201] loss: 1.726\n",
      "[1,   221] loss: 1.674\n",
      "[1,   241] loss: 1.682\n",
      "[1,   261] loss: 1.642\n",
      "[1,   281] loss: 1.632\n",
      "[1,   301] loss: 1.606\n",
      "[1,   321] loss: 1.613\n",
      "[1,   341] loss: 1.574\n",
      "[1,   361] loss: 1.557\n",
      "[1,   381] loss: 1.551\n",
      "[1,   391] loss: 0.780\n",
      "10000张测试集中的准确率为: 44 %\n",
      "Saving..\n",
      "Epoch : 1\n",
      "Best acc :44.04\n",
      "实际的label:       cat     ship     ship    plane\n",
      "预测lable:    cat  ship   car  ship\n",
      "[2,     1] loss: 0.080\n",
      "[2,    21] loss: 1.522\n",
      "[2,    41] loss: 1.531\n",
      "[2,    61] loss: 1.525\n",
      "[2,    81] loss: 1.513\n",
      "[2,   101] loss: 1.533\n",
      "[2,   121] loss: 1.505\n",
      "[2,   141] loss: 1.494\n",
      "[2,   161] loss: 1.463\n",
      "[2,   181] loss: 1.502\n",
      "[2,   201] loss: 1.473\n",
      "[2,   221] loss: 1.435\n",
      "[2,   241] loss: 1.452\n",
      "[2,   261] loss: 1.470\n",
      "[2,   281] loss: 1.463\n",
      "[2,   301] loss: 1.443\n",
      "[2,   321] loss: 1.455\n",
      "[2,   341] loss: 1.407\n",
      "[2,   361] loss: 1.414\n",
      "[2,   381] loss: 1.393\n",
      "[2,   391] loss: 0.689\n",
      "10000张测试集中的准确率为: 49 %\n",
      "Saving..\n",
      "Epoch : 2\n",
      "Best acc :49.61\n",
      "实际的label:      deer      dog     frog      cat\n",
      "预测lable:   bird horse  frog   cat\n",
      "[3,     1] loss: 0.066\n",
      "[3,    21] loss: 1.396\n",
      "[3,    41] loss: 1.374\n",
      "[3,    61] loss: 1.411\n",
      "[3,    81] loss: 1.330\n",
      "[3,   101] loss: 1.355\n",
      "[3,   121] loss: 1.385\n",
      "[3,   141] loss: 1.354\n",
      "[3,   161] loss: 1.341\n",
      "[3,   181] loss: 1.345\n",
      "[3,   201] loss: 1.362\n",
      "[3,   221] loss: 1.318\n",
      "[3,   241] loss: 1.312\n",
      "[3,   261] loss: 1.305\n",
      "[3,   281] loss: 1.366\n",
      "[3,   301] loss: 1.346\n",
      "[3,   321] loss: 1.285\n",
      "[3,   341] loss: 1.311\n",
      "[3,   361] loss: 1.317\n",
      "[3,   381] loss: 1.306\n",
      "[3,   391] loss: 0.642\n",
      "10000张测试集中的准确率为: 53 %\n",
      "Saving..\n",
      "Epoch : 3\n",
      "Best acc :53.54\n",
      "实际的label:       dog      car     ship    horse\n",
      "预测lable:    cat  ship  ship horse\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_epoch = 3\n",
    "dataiter = iter(testloader)\n",
    "for epoch in range(start_epoch, start_epoch+train_epoch):\n",
    "    train(epoch)\n",
    "    #test(epoch)\n",
    "    test2(epoch)\n",
    "    print(\"Epoch : \" + str(epoch+1))\n",
    "    print('Best acc :' + str(best_acc))\n",
    "    images, labels = dataiter.next() # 一个batch返回4张图片\n",
    "    print('实际的label: ', ' '.join(\\\n",
    "                                 '%08s'%classes[labels[j]] for j in range(4)))\n",
    "    show(tv.utils.make_grid(images / 2 - 0.5)).resize((400,100))\n",
    "    #计算图片在每个类别上的分数\n",
    "    outputs = net(images)\n",
    "    # 得分最高的那个类\n",
    "    _, predicted = t.max(outputs.data, 1)\n",
    "    print('预测lable: ', ' '.join('%5s'\\\n",
    "                                % classes[predicted[j]] for j in range(4)))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "test_train_set = tv.datasets.CIFAR100(\n",
    "    root='/home/pakcy/Downloads/pytorch-cifar-master/data', train=True, download=True, transform=test_train_transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "0.5070751592371323\n",
      "0.48654887331495095\n",
      "0.4409178433670343\n",
      "tensor(8.5547, dtype=torch.float64)\n",
      "0.2673342858792409\n",
      "0.25643846291708816\n",
      "0.2761504713256834\n",
      "[0.26733429 0.25643846 0.27615047]\n",
      "0.26733428848992735\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_train_set.train_data.shape)\n",
    "#print(test_train_set.train_data[:,:,:,0].shape)\n",
    "ch0_mean = test_train_set.train_data[:,:,:,0].mean()\n",
    "print(ch0_mean/255)\n",
    "print(test_train_set.train_data[:,:,:,1].mean()/255)\n",
    "print(test_train_set.train_data[:,:,:,2].mean()/255)\n",
    "\n",
    "print(test_train_set.train_data[:,:,:,0].std()/255)\n",
    "print(test_train_set.train_data[:,:,:,1].std()/255)\n",
    "print(test_train_set.train_data[:,:,:,2].std()/255)\n",
    "#print(np.mean(test_train_set.train_data, axis=(0,1,2))/255)\n",
    "print(np.std(test_train_set.train_data,axis=(0,1,2))/255)\n",
    "print(test_train_set.train_data[:,:,:,0].std(ddof=1)/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(63.8333)\n",
      "63.83333206176758\n",
      "tensor([[-62.8333, 270.1667],\n",
      "        [-60.8333, -53.8333],\n",
      "        [-58.8333, -33.8333]])\n",
      "tensor([[ 3948.0276, 72990.0234],\n",
      "        [ 3700.6943,  2898.0276],\n",
      "        [ 3461.3608,  1144.6943]])\n",
      "tensor(88142.8359)\n",
      "tensor(121.2043)\n",
      "tensor(63.8333)\n",
      "tensor(132.7726)\n",
      "132.77261263779766\n",
      "121.20425826769545\n"
     ]
    }
   ],
   "source": [
    "a = t.Tensor([[1,334],[3,10],[5,30]])\n",
    "aa = np.array([[1,334],[3,10],[5,30]])\n",
    "d = a.mean()\n",
    "print(d)\n",
    "print(d.item())\n",
    "\n",
    "print(a-d.item())\n",
    "e = a-d.item()\n",
    "print(e.mul(e))\n",
    "f= (e.mul(e)).sum()\n",
    "print(f)\n",
    "print((((e.mul(e)).sum())/6.0).sqrt())\n",
    "\n",
    "print(a.mean())\n",
    "print(a.std())\n",
    "print(aa.std(ddof=1))\n",
    "print(aa.std(ddof=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
